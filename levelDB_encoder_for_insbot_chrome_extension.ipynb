{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VRHje4nBagVf",
        "-wbdj3SCk7xB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# prerun"
      ],
      "metadata": {
        "id": "VRHje4nBagVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install leveldb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERRE1ykuad5T",
        "outputId": "4e15f370-7666-47b5-dd27-dc10d1393687"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting leveldb\n",
            "  Downloading leveldb-0.201.tar.gz (236 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/236.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/236.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.5/236.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: leveldb\n",
            "  Building wheel for leveldb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for leveldb: filename=leveldb-0.201-cp311-cp311-linux_x86_64.whl size=2049019 sha256=0a7b1c8ccda322e83257fe987f3ef868e60adbc216afe8bf351697a8f50e084f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/bc/56/d98f2bd61408b45fb7504f8689809603ca751cd81b017436e9\n",
            "Successfully built leveldb\n",
            "Installing collected packages: leveldb\n",
            "Successfully installed leveldb-0.201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# engine"
      ],
      "metadata": {
        "id": "-wbdj3SCk7xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import json\n",
        "import csv\n",
        "import glob\n",
        "import struct\n",
        "import leveldb\n",
        "from datetime import datetime\n",
        "\n",
        "def extract_zip(zip_path, extract_path):\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"✅ Extraction complete! Files are saved in: {extract_path}\")\n",
        "\n",
        "def decode_varint(data):\n",
        "    shift = 0\n",
        "    result = 0\n",
        "    for i, byte in enumerate(data):\n",
        "        result |= (byte & 0x7F) << shift\n",
        "        if not (byte & 0x80):\n",
        "            return result, data[i+1:]\n",
        "        shift += 7\n",
        "    return result, data\n",
        "\n",
        "def parse_indexeddb_key(key):\n",
        "    if not key:\n",
        "        return \"Empty Key\"\n",
        "    key_type = key[0]\n",
        "    try:\n",
        "        if key_type == 0x00:\n",
        "            return f\"DatabaseMetadata: {key[1:].hex()}\"\n",
        "        elif key_type == 0x01:\n",
        "            object_store_id, rest = decode_varint(key[1:])\n",
        "            return f\"ObjectStore({object_store_id}): {rest.hex()}\"\n",
        "        elif key_type == 0x02:\n",
        "            object_store_id, rest = decode_varint(key[1:])\n",
        "            index_id, rest = decode_varint(rest)\n",
        "            return f\"Index({object_store_id}, {index_id}): {rest.hex()}\"\n",
        "        elif key_type == 0x03:\n",
        "            object_store_id, rest = decode_varint(key[1:])\n",
        "            index_id, rest = decode_varint(rest)\n",
        "            primary_key, rest = decode_varint(rest)\n",
        "            return f\"IndexKey({object_store_id}, {index_id}, {primary_key}): {rest.hex()}\"\n",
        "        else:\n",
        "            return f\"UnknownKey: {key.hex()}\"\n",
        "    except Exception as e:\n",
        "        return f\"Failed to parse key: {e}\"\n",
        "\n",
        "def scan_leveldb(ldb_path, output_file=\"indexeddb_dump.json\"):\n",
        "    if not os.path.exists(ldb_path):\n",
        "        print(f\"Error: LevelDB path '{ldb_path}' not found!\")\n",
        "        return\n",
        "    db = leveldb.LevelDB(ldb_path)\n",
        "    data = []\n",
        "    for key, value in db.RangeIter():\n",
        "        entry = {\n",
        "            \"ParsedKey\": parse_indexeddb_key(key),\n",
        "            \"RawKey\": key.hex(),\n",
        "            \"Value\": value.decode('utf-8', errors='ignore') if value else \"EMPTY\"\n",
        "        }\n",
        "        data.append(entry)\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "    print(f\"✅ LevelDB scan complete! Data saved to: {output_file}\")\n",
        "\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "# Extract all account entries (accounts do not have an \"actionType\")\n",
        "def extract_all_accounts(data):\n",
        "    accounts = {}\n",
        "    for entry in data:\n",
        "        if \"Value\" in entry:\n",
        "            try:\n",
        "                value = json.loads(entry[\"Value\"])\n",
        "                if isinstance(value, dict) and \"id\" in value and \"actionType\" not in value:\n",
        "                    accounts[str(value[\"id\"])] = value\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "    return accounts\n",
        "\n",
        "# Process actions and collect mentioned account IDs from logs (using \"itemIds\")\n",
        "def process_actions(data):\n",
        "    actions = []\n",
        "    mentioned_account_ids = set()\n",
        "    for entry in data:\n",
        "        if \"Value\" in entry:\n",
        "            try:\n",
        "                value = json.loads(entry[\"Value\"])\n",
        "                if isinstance(value, dict) and \"actionType\" in value:\n",
        "                    actions.append(value)\n",
        "                    if \"logs\" in value:\n",
        "                        for log in value[\"logs\"]:\n",
        "                            if \"itemIds\" in log and isinstance(log[\"itemIds\"], list):\n",
        "                                for account_id in log[\"itemIds\"]:\n",
        "                                    mentioned_account_ids.add(str(account_id))\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "    return actions, mentioned_account_ids\n",
        "\n",
        "def write_action_to_csv(action, index, all_accounts):\n",
        "    # Create a CSV file for the action\n",
        "    filename = f\"action_{index}_{action.get('actionType', 'unknown')}.csv\"\n",
        "    account_count = 0\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"Action Type\", \"Target\", \"Updated At\", \"UUID\", \"Username\", \"Full Name\", \"ID\", \"Is Private\", \"Is Verified\", \"Profile Pic URL\", \"Requested By Viewer\", \"Status\"])\n",
        "        writer.writerow([\n",
        "            action.get(\"actionType\", \"\"),\n",
        "            action.get(\"target\", \"\"),\n",
        "            action.get(\"updatedAt\", \"\"),\n",
        "            action.get(\"uuid\", \"\"),\n",
        "            \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
        "        ])\n",
        "        if \"logs\" in action:\n",
        "            for log in action[\"logs\"]:\n",
        "                if \"itemIds\" in log and isinstance(log[\"itemIds\"], list):\n",
        "                    for account_id in log[\"itemIds\"]:\n",
        "                        aid = str(account_id)\n",
        "                        account = all_accounts.get(aid)\n",
        "                        if account:\n",
        "                            writer.writerow([\n",
        "                                \"\", \"\", \"\", \"\",\n",
        "                                account.get(\"username\", \"\"),\n",
        "                                account.get(\"full_name\", \"\"),\n",
        "                                account.get(\"id\", \"\"),\n",
        "                                account.get(\"is_private\", \"\"),\n",
        "                                account.get(\"is_verified\", \"\"),\n",
        "                                account.get(\"profile_pic_url\", \"\"),\n",
        "                                account.get(\"requested_by_viewer\", \"\"),\n",
        "                                account.get(\"status\", \"\")\n",
        "                            ])\n",
        "                        else:\n",
        "                            writer.writerow([\"\", \"\", \"\", \"\", \"\", \"\", aid, \"\", \"\", \"\", \"\", \"\"])\n",
        "                        account_count += 1\n",
        "    return filename, account_count\n",
        "\n",
        "def write_remaining_accounts_to_csv(remaining_accounts):\n",
        "    filename = \"remained.csv\"\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"Username\", \"Full Name\", \"ID\", \"Is Private\", \"Is Verified\", \"Profile Pic URL\", \"Requested By Viewer\", \"Status\"])\n",
        "        for account in remaining_accounts.values():\n",
        "            writer.writerow([\n",
        "                account.get(\"username\", \"\"),\n",
        "                account.get(\"full_name\", \"\"),\n",
        "                account.get(\"id\", \"\"),\n",
        "                account.get(\"is_private\", \"\"),\n",
        "                account.get(\"is_verified\", \"\"),\n",
        "                account.get(\"profile_pic_url\", \"\"),\n",
        "                account.get(\"requested_by_viewer\", \"\"),\n",
        "                account.get(\"status\", \"\")\n",
        "            ])\n",
        "    return filename\n",
        "\n",
        "def create_output_zip(zip_filename=\"output.zip\"):\n",
        "    # List of files to include\n",
        "    files_to_zip = []\n",
        "    # Include the JSON dump if it exists\n",
        "    if os.path.exists(\"indexeddb_dump.json\"):\n",
        "        files_to_zip.append(\"indexeddb_dump.json\")\n",
        "    # Include all action CSV files\n",
        "    files_to_zip.extend(glob.glob(\"action_*.csv\"))\n",
        "    # Include the remained CSV file if exists\n",
        "    if os.path.exists(\"remained.csv\"):\n",
        "        files_to_zip.append(\"remained.csv\")\n",
        "\n",
        "    # Create zip archive and add files\n",
        "    with zipfile.ZipFile(zip_filename, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for f in files_to_zip:\n",
        "            zipf.write(f)\n",
        "    print(f\"✅ All output files have been zipped into: {zip_filename}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "P_-89t86XQOS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run"
      ],
      "metadata": {
        "id": "JalckjOlXWB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    # Step 1: Extract the provided zip file\n",
        "    zip_path = \"h.zip\"                # Your input zip file\n",
        "    extract_path = \"./extracted\"        # Extraction folder\n",
        "    folder_name = \"h\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #------------------------\n",
        "    extract_zip(zip_path, extract_path)\n",
        "\n",
        "    # Step 2: Scan LevelDB from the extracted folder and create JSON dump\n",
        "    ldb_path = os.path.join(extract_path, folder_name)\n",
        "    scan_leveldb(ldb_path)\n",
        "\n",
        "    # Step 3: Process the JSON dump to extract accounts and actions\n",
        "    data = load_json(\"indexeddb_dump.json\")\n",
        "    all_accounts = extract_all_accounts(data)\n",
        "    actions, mentioned_account_ids = process_actions(data)\n",
        "\n",
        "    # Step 4: Write CSV files for each action\n",
        "    total_action_accounts = 0\n",
        "    for i, action in enumerate(actions, start=1):\n",
        "        csv_file, count = write_action_to_csv(action, i, all_accounts)\n",
        "        print(f\"CSV file created: {csv_file} | Accounts in action: {count}\")\n",
        "        total_action_accounts += count\n",
        "\n",
        "    # Step 5: Write CSV for remaining accounts not mentioned in any action\n",
        "    remaining_accounts = {aid: acct for aid, acct in all_accounts.items() if aid not in mentioned_account_ids}\n",
        "    remained_csv = write_remaining_accounts_to_csv(remaining_accounts)\n",
        "\n",
        "    # Step 6: Print analysis\n",
        "    total_mentioned_ids = sum(len(log.get(\"itemIds\", [])) for action in actions for log in action.get(\"logs\", []))\n",
        "    print(\"\\n--- Analysis ---\")\n",
        "    print(f\"Total actions found: {len(actions)}\")\n",
        "    print(f\"Total accounts found: {len(all_accounts)}\")\n",
        "    print(f\"Total accounts mentioned in actions (from logs): {total_mentioned_ids}\")\n",
        "    print(f\"Total accounts in actions (written to CSV): {total_action_accounts}\")\n",
        "    print(f\"Remaining accounts not mentioned in any action: {len(remaining_accounts)}\")\n",
        "    print(f\"Total accounts overall: {total_action_accounts + len(remaining_accounts)}\")\n",
        "    print(f\"CSV file created for remaining accounts: {remained_csv}\")\n",
        "\n",
        "    # Step 7: Zip all output files\n",
        "    create_output_zip()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uBLfSxMXXC3",
        "outputId": "df7486d7-f7fa-4a23-de15-1c02d1d59284"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction complete! Files are saved in: ./extracted\n",
            "✅ LevelDB scan complete! Data saved to: indexeddb_dump.json\n",
            "CSV file created: action_1_unfollow.csv | Accounts in action: 207\n",
            "CSV file created: action_2_unfollow.csv | Accounts in action: 0\n",
            "CSV file created: action_3_follow.csv | Accounts in action: 60\n",
            "CSV file created: action_4_unfollow.csv | Accounts in action: 0\n",
            "CSV file created: action_5_unfollow.csv | Accounts in action: 0\n",
            "CSV file created: action_6_unfollow.csv | Accounts in action: 0\n",
            "CSV file created: action_7_unfollow.csv | Accounts in action: 1200\n",
            "CSV file created: action_8_unfollow.csv | Accounts in action: 1418\n",
            "CSV file created: action_9_unfollow.csv | Accounts in action: 1407\n",
            "CSV file created: action_10_follow.csv | Accounts in action: 74\n",
            "CSV file created: action_11_unfollow.csv | Accounts in action: 0\n",
            "CSV file created: action_12_unfollow.csv | Accounts in action: 0\n",
            "CSV file created: action_13_unfollow.csv | Accounts in action: 0\n",
            "CSV file created: action_14_unfollow.csv | Accounts in action: 801\n",
            "\n",
            "--- Analysis ---\n",
            "Total actions found: 14\n",
            "Total accounts found: 5169\n",
            "Total accounts mentioned in actions (from logs): 5167\n",
            "Total accounts in actions (written to CSV): 5167\n",
            "Remaining accounts not mentioned in any action: 3\n",
            "Total accounts overall: 5170\n",
            "CSV file created for remaining accounts: remained.csv\n",
            "✅ All output files have been zipped into: output.zip\n"
          ]
        }
      ]
    }
  ]
}
